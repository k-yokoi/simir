{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os.path\n",
    "import psycopg2\n",
    "from gensim.models import Doc2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import re\n",
    "import linecache\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, Input, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.utils import np_utils, Sequence\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_vec_dim = 88\n",
    "embedding_dim = 6\n",
    "dim = 128\n",
    "keep_prob = 0.6\n",
    "\n",
    "batch_size = 256\n",
    "test_size = 256\n",
    "\n",
    "\n",
    "# disable tensorflow debugging information\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "logdir = '/tmp/logs'\n",
    "\n",
    "kernel_init = K.initializers.VarianceScaling(scale=1.0, mode='fan_avg',\n",
    "                                             distribution='uniform')\n",
    "bias_init = K.initializers.Constant(value=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = pd.read_csv('E:\\k-yokoi\\IJaDataset2.0-full-functions2\\\\functions.csv', names=('id', 'document'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "functionality_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(sql):\n",
    "    connection = psycopg2.connect(\"host=localhost port=5432 dbname=bigclonebench user=postgres password=1994MomJul\")\n",
    "    connection.get_backend_pid()\n",
    "    cur=connection.cursor()\n",
    "    cur.execute(sql)\n",
    "    results = [row for row in cur]\n",
    "\n",
    "    cur.close()\n",
    "    connection.close()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and functionality_id=' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "train_All_clones = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and functionality_id<>' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "test_All_clones = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=1 and functionality_id=' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "train_T1 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=1 and functionality_id<>' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "test_T1 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=2 and functionality_id=' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "train_T2 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=2 and functionality_id<>' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "test_T2 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=3 and similarity_token>=0.9 and functionality_id=' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "train_VST3 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=3 and similarity_token>=0.9 and functionality_id<>' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "test_VST3 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=3 and similarity_token>=0.7 and similarity_token<0.9 and functionality_id=' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "train_ST3 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=3 and similarity_token>=0.7 and similarity_token<0.9 and functionality_id<>' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "test_ST3 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=3 and similarity_token>=0.5 and similarity_token<0.7 and functionality_id=' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "train_MT3 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=3 and similarity_token>=0.5 and similarity_token<0.7 and functionality_id<>' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "test_MT3 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=3 and similarity_token<0.5 and functionality_id=' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "train_WT3T4 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select function_id_one, function_id_two from clones where min_size >= 5 and syntactic_type=3 and similarity_token<0.5 and functionality_id<>' + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "test_WT3T4 = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT FP.function_id_one, FP.function_id_two from false_positives as FP, functions as A, functions as B \"\n",
    "sql += \"where FP.function_id_one=A.id and FP.function_id_two=B.id and \"\n",
    "sql += \"A.normalized_size>=5 and B.normalized_size>=5 and \"\n",
    "sql += \"FP.functionality_id=\" + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "train_All_FP = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT FP.function_id_one, FP.function_id_two from false_positives as FP, functions as A, functions as B \"\n",
    "sql += \"where FP.function_id_one=A.id and FP.function_id_two=B.id and \"\n",
    "sql += \"A.normalized_size>=5 and B.normalized_size>=5 and \"\n",
    "sql += \"FP.functionality_id<>\" + str(functionality_id)\n",
    "tmp = execute_sql(sql)\n",
    "\n",
    "function_id_set = set(functions['id'])\n",
    "test_All_FP = [row for row in tmp if row[0] in function_id_set and row[1] in function_id_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clones= pd.DataFrame(clones, columns=['id_one', 'id_two'])\n",
    "df_clones['clone'] = 1\n",
    "df_fp= pd.DataFrame(FP, columns=['id_one', 'id_two'])\n",
    "df_fp['clone'] = 0\n",
    "df_clones = df_clones.append(df_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dv = np.load('model/scdvnoidf.dv.npy')\n",
    "#dv = np.load('model/AvgVec.dv.npy')\n",
    "#dv = np.load('model/LSI.dv.npy')\n",
    "#dv = np.load('model/LDA.dv.npy')\n",
    "docmodel = Doc2Vec.load(\"model/pvdbow.model\")\n",
    "#docmodel = Doc2Vec.load(\"model/pvdm.model\")\n",
    "dv = docmodel.docvecs.vectors_docs\n",
    "\n",
    "bin_vec_dim = dv.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_dict = {}\n",
    "for i, id in enumerate(functions['id']):\n",
    "    dv_dict[id] = dv[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13798\n",
      "2361\n"
     ]
    }
   ],
   "source": [
    "train_clones = train_T1\n",
    "test_clones = test_T1\n",
    "print(len(train_clones))\n",
    "print(len(test_clones))\n",
    "import random\n",
    "random.seed(0)\n",
    "train_FP = random.sample(train_All_FP, min(len(train_clones), len(train_All_FP)))\n",
    "test_FP = random.sample(test_All_FP, min(len(test_clones), len(test_All_FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_left = [dv_dict[x[0]] for x in train_clones]\n",
    "train_X_left.extend([dv_dict[x[0]] for x in train_FP])\n",
    "train_X_right = [dv_dict[x[1]] for x in train_clones]\n",
    "train_X_right.extend([dv_dict[x[1]] for x in train_FP])\n",
    "\n",
    "train_X_left = np.array(train_X_left)\n",
    "train_X_right = np.array(train_X_right)\n",
    "train_Y = np.hstack((np.ones(len(train_clones)), np.zeros(len(train_FP))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_left = [dv_dict[x[0]] for x in test_clones]\n",
    "test_X_left.extend([dv_dict[x[0]] for x in test_FP])\n",
    "test_X_right = [dv_dict[x[1]] for x in test_clones]\n",
    "test_X_right.extend([dv_dict[x[1]] for x in test_FP])\n",
    "\n",
    "test_X_left = np.array(test_X_left)\n",
    "test_X_right = np.array(test_X_right)\n",
    "test_Y = np.hstack((np.ones(len(test_clones)), np.zeros(len(test_FP))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_left, train_X_right, train_Y = shuffle(train_X_left, train_X_right, train_Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_left, test_X_right, test_Y = shuffle(test_X_left, test_X_right, test_Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "27596/27596 [==============================] - 2s 63us/step - loss: 0.0566 - acc: 0.9826\n",
      "Epoch 2/4\n",
      "27596/27596 [==============================] - 1s 20us/step - loss: 0.0163 - acc: 0.9964\n",
      "Epoch 3/4\n",
      "27596/27596 [==============================] - 1s 18us/step - loss: 0.0083 - acc: 0.9983\n",
      "Epoch 4/4\n",
      "27596/27596 [==============================] - 0s 17us/step - loss: 0.0043 - acc: 0.9993\n",
      "4722/4722 [==============================] - 0s 87us/step\n",
      "accuracy: 0.5066, recall: 0.0140, precision: 0.9429, f1 score: 0.0275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_left = Input(shape=(bin_vec_dim, ))\n",
    "X_right = Input(shape=(bin_vec_dim, ))\n",
    "\n",
    "predictions = classification(X_left, X_right)\n",
    "\n",
    "model = Model(inputs=[X_left, X_right], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=K.optimizers.adam(lr=0.001),\n",
    "              loss=K.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "model.fit([train_X_left, train_X_right], train_Y,\n",
    "          epochs=4,verbose=1, batch_size=batch_size)\n",
    "y_pred = model.predict([test_X_left, test_X_right], verbose=1, batch_size=batch_size)\n",
    "y_pred = np.round(y_pred)\n",
    "accuracy = accuracy_score(test_Y, y_pred)\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(test_Y,\n",
    "                                                         y_pred, average='binary')\n",
    "print(\"accuracy: %.4f, recall: %.4f, \"\n",
    "           \"precision: %.4f, f1 score: %.4f\\n\" % (\n",
    "           accuracy, recall, precision, fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "test_clones_T = test_T1\n",
    "test_FP_T = random.sample(test_FP, min(len(test_clones_T), len(test_FP)))\n",
    "\n",
    "\n",
    "test_X_left = [dv_dict[x[0]] for x in test_clones_T]\n",
    "test_X_left.extend([dv_dict[x[0]] for x in test_FP_T])\n",
    "test_X_right = [dv_dict[x[1]] for x in test_clones_T]\n",
    "test_X_right.extend([dv_dict[x[1]] for x in test_FP_T])\n",
    "\n",
    "test_X_left = np.array(test_X_left)\n",
    "test_X_right = np.array(test_X_right)\n",
    "test_Y = np.hstack((np.ones(len(test_clones_T)), np.zeros(len(test_FP_T))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1373814"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_clones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4722/4722 [==============================] - 0s 93us/step\n",
      "accuracy: 0.5517, recall: 0.7810, precision: 0.5354, f1 score: 0.6353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_X_left, test_X_right, test_Y = shuffle(test_X_left, test_X_right, test_Y, random_state=0)\n",
    "\n",
    "X_left = Input(shape=(bin_vec_dim, ))\n",
    "X_right = Input(shape=(bin_vec_dim, ))\n",
    "\n",
    "predictions = classification(X_left, X_right)\n",
    "\n",
    "y_pred = model.predict([test_X_left, test_X_right], verbose=1, batch_size=batch_size)\n",
    "y_pred = np.round(y_pred)\n",
    "accuracy = accuracy_score(test_Y, y_pred)\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(test_Y,\n",
    "                                                         y_pred, average='binary')\n",
    "print(\"accuracy: %.4f, recall: %.4f, \"\n",
    "           \"precision: %.4f, f1 score: %.4f\\n\" % (\n",
    "           accuracy, recall, precision, fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ok\":true,\"channel\":\"G7LJMJJTE\",\"ts\":\"1545288518.000100\",\"message\":{\"type\":\"message\",\"subtype\":\"bot_message\",\"text\":\"finish\",\"ts\":\"1545288518.000100\",\"username\":\"bot\",\"bot_id\":\"B7LJJJEQ4\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   323    0   190  100   133    608    426 --:--:-- --:--:-- --:--:--  1035\n"
     ]
    }
   ],
   "source": [
    "!slack-post finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(x1, x2):\n",
    "    input = Input(shape=(bin_vec_dim,))\n",
    "    # share layers\n",
    "    #feed_forward_model = Model(inputs=input, outputs=feed_forward(input))\n",
    "    #x1 = feed_forward_model(x1)\n",
    "    #x2 = feed_forward_model(x2)\n",
    "    concat_input = Input(shape=(bin_vec_dim*2,))\n",
    "    # share layers\n",
    "    merge_model = Model(inputs=concat_input,\n",
    "                        outputs=Activation(activation='relu')(\n",
    "                            BatchNormalization()(\n",
    "                                Dense(100, kernel_initializer=kernel_init,\n",
    "                                      bias_initializer=bias_init,\n",
    "                                      input_shape=(bin_vec_dim*2,))(\n",
    "                                    concat_input))))\n",
    "    \n",
    "    xc1 = K.layers.concatenate([x1, x2])\n",
    "    xc1 = merge_model(xc1)\n",
    "    \n",
    "    xc2 = K.layers.concatenate([x2, x1])\n",
    "    xc2 = merge_model(xc2)\n",
    "    \n",
    "    xc = K.layers.average([xc1, xc2])\n",
    "    \n",
    "    x = Dense(1, use_bias=False, activation='sigmoid',\n",
    "              kernel_initializer=kernel_init,\n",
    "              batch_input_shape=K.backend.get_variable_shape(xc))(xc)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
